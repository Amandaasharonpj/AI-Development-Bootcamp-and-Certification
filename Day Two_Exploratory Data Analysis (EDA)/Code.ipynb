{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "373485af",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "is the process of understanding data structure, summarizing key features, finding missing or incorrect values, preparing the data for ml models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c202d8a0",
   "metadata": {},
   "source": [
    "### Loading and Inspecting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd645ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   application_id  gender  international   gpa       major      race   gmat  \\\n",
      "0               1  Female          False  3.30    Business     Asian  620.0   \n",
      "1               2    Male          False  3.28  Humanities     Black  680.0   \n",
      "2               3  Female           True  3.30    Business       NaN  710.0   \n",
      "3               4    Male          False  3.47        STEM     Black  690.0   \n",
      "4               5    Male          False  3.35        STEM  Hispanic  590.0   \n",
      "\n",
      "   work_exp          work_industry admission  \n",
      "0       3.0     Financial Services     Admit  \n",
      "1       5.0  Investment Management       NaN  \n",
      "2       5.0             Technology     Admit  \n",
      "3       6.0             Technology       NaN  \n",
      "4       5.0             Consulting       NaN  \n",
      "(6194, 10)\n",
      "Index(['application_id', 'gender', 'international', 'gpa', 'major', 'race',\n",
      "       'gmat', 'work_exp', 'work_industry', 'admission'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6194 entries, 0 to 6193\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   application_id  6194 non-null   int64  \n",
      " 1   gender          6194 non-null   object \n",
      " 2   international   6194 non-null   bool   \n",
      " 3   gpa             6194 non-null   float64\n",
      " 4   major           6194 non-null   object \n",
      " 5   race            4352 non-null   object \n",
      " 6   gmat            6194 non-null   float64\n",
      " 7   work_exp        6194 non-null   float64\n",
      " 8   work_industry   6194 non-null   object \n",
      " 9   admission       1000 non-null   object \n",
      "dtypes: bool(1), float64(3), int64(1), object(5)\n",
      "memory usage: 441.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Load CSV File \n",
    "data = pd.read_csv('MBA.csv')\n",
    "\n",
    "print(data.head()) \n",
    "\n",
    "#Inspecting Data Structure \n",
    "\n",
    "#How many rows and columns \n",
    "print(data.shape)\n",
    "\n",
    "#What are the columns name's that we have \n",
    "print(data.columns)\n",
    "\n",
    "#Summary of the entire dataset : column types, non-null count\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b06a7cb",
   "metadata": {},
   "source": [
    "### Handling Missing Data\n",
    "1. Drop the missing data\n",
    "2. Fill with mean - It keeps the average of the data unchanged and is useful when values are normally distributed (not too many outliers).\n",
    "3. Fill with placeholder (like 0 or \"Unknown\") - useful for categorical data where there's no numerical logic, and you want to keep the row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c5db639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "application_id       0\n",
      "gender               0\n",
      "international        0\n",
      "gpa                  0\n",
      "major                0\n",
      "race              1842\n",
      "gmat                 0\n",
      "work_exp             0\n",
      "work_industry        0\n",
      "admission         5194\n",
      "dtype: int64\n",
      "application_id    0\n",
      "gender            0\n",
      "international     0\n",
      "gpa               0\n",
      "major             0\n",
      "race              0\n",
      "gmat              0\n",
      "work_exp          0\n",
      "work_industry     0\n",
      "admission         0\n",
      "dtype: int64\n",
      "application_id       0\n",
      "gender               0\n",
      "international        0\n",
      "gpa                  0\n",
      "major                0\n",
      "race                 0\n",
      "gmat                 0\n",
      "work_exp             0\n",
      "work_industry        0\n",
      "admission         5194\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data1 = pd.read_csv('MBA.csv')\n",
    "\n",
    "# Identifying missing value \n",
    "print(data1.isnull().sum())\n",
    "\n",
    "# How we handle missing data \n",
    "\n",
    "# Drop the missing values \n",
    "data_clean = data1.dropna()\n",
    "print(data_clean.isnull().sum())\n",
    "\n",
    "# Fill missing values in 'work_exp' column with the mean of that column\n",
    "mean_value = data1['work_exp'].mean()\n",
    "data1['work_exp'].fillna(mean_value, inplace=True)\n",
    "\n",
    "# Fill missing value with a placeholder value\n",
    "data1['race'].fillna(\"Unknown\", inplace=True)\n",
    "print(data1.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0831ef6d",
   "metadata": {},
   "source": [
    "### Data Transformation and Feature Engineering\n",
    "Feature Scalling and Catagorical Data Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39f9d27d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MinMaxScaler\n\u001b[0;32m      5\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[1;32m----> 7\u001b[0m data2 [[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIncome\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform (\u001b[43mdata2\u001b[49m[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIncome\u001b[39m\u001b[38;5;124m'\u001b[39m]])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data2' is not defined"
     ]
    }
   ],
   "source": [
    "# Feature scalling - numerical feature around same scale / Normalisation \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "data2 [['Age', 'Income']] = scaler.fit_transform (data2[['Age', 'Income']]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c20daa7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Gender', 'Purchased'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_encoded \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dummies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGender\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPurchased\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py:890\u001b[0m, in \u001b[0;36mget_dummies\u001b[1;34m(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\u001b[0m\n\u001b[0;32m    888\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput must be a list-like for parameter `columns`\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 890\u001b[0m     data_to_encode \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[38;5;66;03m# validate prefixes and separator to avoid silently dropping cols\u001b[39;00m\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_len\u001b[39m(item, name):\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3464\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3462\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   3463\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 3464\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_listlike_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   3466\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   3467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1314\u001b[0m, in \u001b[0;36m_LocIndexer._get_listlike_indexer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1311\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1312\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 1314\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_read_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m needs_i8_conversion(ax\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m   1317\u001b[0m     ax, (IntervalIndex, CategoricalIndex)\n\u001b[0;32m   1318\u001b[0m ):\n\u001b[0;32m   1319\u001b[0m     \u001b[38;5;66;03m# For CategoricalIndex take instead of reindex to preserve dtype.\u001b[39;00m\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;66;03m#  For IntervalIndex this is to map integers to the Intervals they match to.\u001b[39;00m\n\u001b[0;32m   1321\u001b[0m     keyarr \u001b[38;5;241m=\u001b[39m ax\u001b[38;5;241m.\u001b[39mtake(indexer)\n",
      "File \u001b[1;32mc:\\Users\\ASUS\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1374\u001b[0m, in \u001b[0;36m_LocIndexer._validate_read_indexer\u001b[1;34m(self, key, indexer, axis)\u001b[0m\n\u001b[0;32m   1372\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_interval_msg:\n\u001b[0;32m   1373\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 1374\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1376\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['Gender', 'Purchased'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "data_encoded = pd.get_dummies(data, columns=['Gender', 'Purchased'] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
